{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aa81a546",
      "metadata": {},
      "source": [
        "## **Config (paths, model names, imports)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "97604a2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Suppress HuggingFace tokenizers parallelism warning in Jupyter notebooks\n",
        "# This prevents the \"forked process\" warning when using HuggingFaceEmbeddings\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "\n",
        "# Set LangChain configuration from environment variables\n",
        "os.environ['LANGSMITH_TRACING'] = os.getenv('LANGSMITH_TRACING')\n",
        "os.environ['LANGSMITH_ENDPOINT'] = os.getenv('LANGSMITH_ENDPOINT')\n",
        "os.environ['LANGSMITH_API_KEY'] = os.getenv('LANGSMITH_API_KEY')    \n",
        "os.environ['LANGSMITH_PROJECT'] = os.getenv('LANGSMITH_PROJECT')\n",
        "\n",
        "#API KEY\n",
        "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b94a25dd",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/dimitar/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Necessary packages\n",
        "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c9ef136",
      "metadata": {},
      "source": [
        "## **Extract metadata from mkdocs.yml**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a55cf381",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total documents in navigation: 144\n",
            "\n",
            "Example metadata entries:\n",
            "\n",
            "1. index.md\n",
            "   Category Path: FastAPI\n",
            "   Top Level: FastAPI\n",
            "\n",
            "2. features.md\n",
            "   Category Path: \n",
            "   Top Level: Root\n",
            "\n",
            "3. learn/index.md\n",
            "   Category Path: Learn\n",
            "   Top Level: Learn\n",
            "   Subcategory: Learn\n",
            "\n",
            "4. python-types.md\n",
            "   Category Path: Learn\n",
            "   Top Level: Learn\n",
            "   Subcategory: Learn\n",
            "\n",
            "5. async.md\n",
            "   Category Path: Learn\n",
            "   Top Level: Learn\n",
            "   Subcategory: Learn\n"
          ]
        }
      ],
      "source": [
        "# Load mkdocs.yml configuration\n",
        "# Get the project root directory by checking for fastapi directory\n",
        "current_dir = Path.cwd()\n",
        "# Check if fastapi directory exists in current dir or parent\n",
        "if (current_dir / \"fastapi\").exists():\n",
        "    project_root = current_dir\n",
        "elif (current_dir.parent / \"fastapi\").exists():\n",
        "    project_root = current_dir.parent\n",
        "else:\n",
        "    # Fallback: assume parent directory (notebook is in rag-learning/rag-learning/)\n",
        "    project_root = current_dir.parent\n",
        "\n",
        "mkdocs_path = project_root / \"fastapi\" / \"docs\" / \"en\" / \"mkdocs.yml\"\n",
        "docs_base_path = project_root / \"fastapi\" / \"docs\" / \"en\" / \"docs\"\n",
        "\n",
        "# Convert to string for compatibility\n",
        "mkdocs_path = str(mkdocs_path)\n",
        "docs_base_path = str(docs_base_path)\n",
        "\n",
        "# Pre-process the YAML file to handle the problematic !!python/name: tag\n",
        "# We'll replace it with a null value since we only need the 'nav' section\n",
        "import re\n",
        "\n",
        "with open(mkdocs_path, 'r') as f:\n",
        "    yaml_content = f.read()\n",
        "    \n",
        "# Replace the problematic Python tag with null using regex\n",
        "# This handles the tag whether it's on its own or part of a value\n",
        "yaml_content = re.sub(r'!!python/name:[^\\s]+', 'null', yaml_content)\n",
        "\n",
        "# Now parse the cleaned YAML\n",
        "mkdocs_config = yaml.safe_load(yaml_content)\n",
        "\n",
        "# Extract navigation structure\n",
        "nav_structure = mkdocs_config.get('nav', [])\n",
        "\n",
        "# Build a mapping from file paths to their metadata\n",
        "def extract_nav_metadata(nav_items: List[Any], parent_path: List[str] = None) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Recursively extract navigation metadata from mkdocs nav structure.\n",
        "    Returns a dictionary mapping file paths to their metadata.\n",
        "    \"\"\"\n",
        "    if parent_path is None:\n",
        "        parent_path = []\n",
        "    \n",
        "    metadata_map = {}\n",
        "    \n",
        "    for item in nav_items:\n",
        "        if isinstance(item, dict):\n",
        "            # Handle dictionary items (e.g., {\"Tutorial - User Guide\": [...]})\n",
        "            for key, value in item.items():\n",
        "                if isinstance(value, list):\n",
        "                    # Recursive case: nested navigation\n",
        "                    new_path = parent_path + [key]\n",
        "                    metadata_map.update(extract_nav_metadata(value, new_path))\n",
        "                elif isinstance(value, str):\n",
        "                    # Leaf case: key is section name, value is file path\n",
        "                    file_path = value\n",
        "                    metadata_map[file_path] = {\n",
        "                        'section': key,\n",
        "                        'category_path': parent_path + [key],\n",
        "                        'top_level_category': parent_path[0] if parent_path else key,\n",
        "                        'subcategory': parent_path[-1] if len(parent_path) > 1 else None,\n",
        "                    }\n",
        "        elif isinstance(item, str):\n",
        "            # Handle simple string items (e.g., \"tutorial/first-steps.md\")\n",
        "            file_path = item\n",
        "            metadata_map[file_path] = {\n",
        "                'section': None,\n",
        "                'category_path': parent_path.copy(),\n",
        "                'top_level_category': parent_path[0] if parent_path else 'Root',\n",
        "                'subcategory': parent_path[-1] if parent_path else None,\n",
        "            }\n",
        "    \n",
        "    return metadata_map\n",
        "\n",
        "# Create the metadata mapping\n",
        "nav_metadata_map = extract_nav_metadata(nav_structure)\n",
        "\n",
        "# Display some examples\n",
        "print(f\"Total documents in navigation: {len(nav_metadata_map)}\")\n",
        "print(\"\\nExample metadata entries:\")\n",
        "for i, (path, meta) in enumerate(list(nav_metadata_map.items())[:5]):\n",
        "    print(f\"\\n{i+1}. {path}\")\n",
        "    print(f\"   Category Path: {' > '.join(meta['category_path'])}\")\n",
        "    print(f\"   Top Level: {meta['top_level_category']}\")\n",
        "    if meta['subcategory']:\n",
        "        print(f\"   Subcategory: {meta['subcategory']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c5f34bb",
      "metadata": {},
      "source": [
        "## **Build dense vs lightweight corpora**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "10696917",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample enriched document metadata:\n",
            "{'source': '/Users/dimitar/Desktop/Software_Dev/rag-learning/fastapi/docs/en/docs/tutorial/query-params.md', 'corpus': 'dense_docs', 'section': None, 'category_path': 'Learn > Tutorial - User Guide', 'top_level_category': 'Learn', 'subcategory': 'Tutorial - User Guide'}\n"
          ]
        }
      ],
      "source": [
        "# Helper function to enrich documents with mkdocs metadata\n",
        "def enrich_document_metadata(doc, metadata_map: Dict[str, Dict[str, Any]], docs_base_path: str):\n",
        "    \"\"\"Add mkdocs navigation metadata to a document based on its file path.\"\"\"\n",
        "    # Get the relative path from the document's source\n",
        "    source_path = doc.metadata.get('source', '')\n",
        "    \n",
        "    # Convert absolute path to relative path from docs base\n",
        "    if source_path.startswith(docs_base_path):\n",
        "        relative_path = source_path[len(docs_base_path):].lstrip('/')\n",
        "        \n",
        "        # Normalize paths for comparison (handle both with/without .md extension)\n",
        "        relative_path_normalized = relative_path.replace('.md', '')\n",
        "        \n",
        "        # Try exact match first\n",
        "        if relative_path in metadata_map:\n",
        "            nav_meta = metadata_map[relative_path]\n",
        "        else:\n",
        "            # Try matching by normalized path (without .md)\n",
        "            nav_meta = None\n",
        "            for nav_path, meta in metadata_map.items():\n",
        "                nav_path_normalized = nav_path.replace('.md', '')\n",
        "                # Match if paths are the same when normalized\n",
        "                if nav_path_normalized == relative_path_normalized:\n",
        "                    nav_meta = meta\n",
        "                    break\n",
        "                # Also try if the relative path ends with the nav path\n",
        "                if relative_path.endswith(nav_path) or nav_path in relative_path:\n",
        "                    nav_meta = meta\n",
        "                    break\n",
        "        \n",
        "        # Add metadata if found\n",
        "        if nav_meta:\n",
        "            doc.metadata['section'] = nav_meta.get('section')\n",
        "            doc.metadata['category_path'] = ' > '.join(nav_meta.get('category_path', []))\n",
        "            doc.metadata['top_level_category'] = nav_meta.get('top_level_category')\n",
        "            doc.metadata['subcategory'] = nav_meta.get('subcategory')\n",
        "    \n",
        "    return doc\n",
        "\n",
        "# Dense corpus: tutorials + advanced guides\n",
        "dense_loader = DirectoryLoader(\n",
        "    docs_base_path,\n",
        "    glob=\"tutorial/**/*.md\",\n",
        "    loader_cls=TextLoader,\n",
        ")\n",
        "dense_docs = dense_loader.load()\n",
        "for d in dense_docs:\n",
        "    d.metadata[\"corpus\"] = \"dense_docs\"\n",
        "    # Enrich with mkdocs metadata\n",
        "    enrich_document_metadata(d, nav_metadata_map, docs_base_path)\n",
        "\n",
        "# Lightweight corpus: e.g. fastapi-best-practices repo\n",
        "faq_path = project_root / \"fastapi-best-practices\"\n",
        "faq_loader = DirectoryLoader(\n",
        "    str(faq_path),\n",
        "    glob=\"README.md\",\n",
        "    loader_cls=TextLoader,\n",
        ")\n",
        "faq_docs = faq_loader.load()\n",
        "for d in faq_docs:\n",
        "    d.metadata[\"corpus\"] = \"faq_docs\"\n",
        "\n",
        "# Display enriched metadata\n",
        "print(\"Sample enriched document metadata:\")\n",
        "print(dense_docs[2].metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ba5dcc60",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "from datetime import date\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class FastAPISearch(BaseModel):\n",
        "    \"\"\"\n",
        "    Structured query for searching over FastAPI documentation chunks.\n",
        "    The LLM will fill this from a natural-language question.\n",
        "    \"\"\"\n",
        "\n",
        "    # What to search for semantically\n",
        "    text: str = Field(\n",
        "        ...,\n",
        "        description=(\n",
        "            \"Main semantic search query over the document content. \"\n",
        "            \"Use natural language describing the user's problem or question.\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # High-level doc classification\n",
        "    top_level_category: Optional[str] = Field(\n",
        "        None,\n",
        "        description=(\n",
        "            \"Top-level documentation category, such as 'Learn', \"\n",
        "            \"'Reference', or 'Tutorials'. \"\n",
        "            \"Use when the user seems to want conceptual/how-to material \"\n",
        "            \"vs pure API reference.\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    subcategory: Optional[str] = Field(\n",
        "        None,\n",
        "        description=(\n",
        "            \"More specific documentation subcategory, such as \"\n",
        "            \"'Tutorial - User Guide', 'Advanced User Guide', etc. \"\n",
        "            \"Use when the user implicitly asks for guides or tutorials.\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    corpus: Optional[str] = Field(\n",
        "        None,\n",
        "        description=(\n",
        "            \"Internal corpus label (for example 'dense_docs', 'api_reference', \"\n",
        "            \"'examples'). Use when the user implicitly wants a particular type \"\n",
        "            \"of docs (e.g., reference vs prose).\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Optional filters you might add later if your metadata has them\n",
        "    earliest_publish_date: Optional[date] = Field(\n",
        "        None,\n",
        "        description=(\n",
        "            \"Earliest publish date for documents, inclusive. \"\n",
        "            \"Use only if the user explicitly cares about recent or old docs.\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    latest_publish_date: Optional[date] = Field(\n",
        "        None,\n",
        "        description=(\n",
        "            \"Latest publish date for documents, exclusive. \"\n",
        "            \"Use only if the user explicitly limits the time range.\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    def pretty_print(self) -> None:\n",
        "        # Access model_fields from the class, not the instance (Pydantic v2.11+)\n",
        "        model_fields = self.__class__.model_fields\n",
        "        for field_name in model_fields.keys():\n",
        "            field_value = getattr(self, field_name, None)\n",
        "            field_info = model_fields[field_name]\n",
        "            # Get default value, handling Pydantic v2 FieldInfo structure\n",
        "            default_value = getattr(field_info, 'default', None)\n",
        "            # Skip if value is None or equals the default\n",
        "            if field_value is not None and field_value != default_value:\n",
        "                print(f\"{field_name}: {field_value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "716e26ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "system = \"\"\"You are an assistant that converts natural language questions\n",
        "into structured search queries for the FastAPI documentation.\n",
        "\n",
        "Your job is to:\n",
        "- Extract a semantic search text that captures the user's problem or topic.\n",
        "- Set metadata fields (top_level_category, subcategory, corpus, etc.)\n",
        "  only when they are clearly implied by the question.\n",
        "\n",
        "If you are unsure about a field, leave it empty (null).\n",
        "Do NOT invent metadata values that are not supported by the schema.\n",
        "Do NOT try to expand or reinterpret unknown acronyms; keep them as-is.\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0)  # or any chat model\n",
        "structured_llm = llm.with_structured_output(FastAPISearch)\n",
        "query_analyzer = prompt | structured_llm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7d8e390",
      "metadata": {},
      "source": [
        "## **Chunk + embed + index (two vector stores)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a8190ef2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dense chunks: 388\n",
            "FAQ chunks:   42\n"
          ]
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
        "    chunk_overlap=150,\n",
        "    length_function=len,)\n",
        "\n",
        "# dense_docs and faq_docs already loaded and metadata-enriched earlier\n",
        "dense_chunks = text_splitter.split_documents(dense_docs)\n",
        "faq_chunks = text_splitter.split_documents(faq_docs)\n",
        "\n",
        "print(f\"Dense chunks: {len(dense_chunks)}\")\n",
        "print(f\"FAQ chunks:   {len(faq_chunks)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "99b5f582",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Embedding\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "04091bbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "vectordb_dir = Path(\"chroma_fastapi\")\n",
        "vectordb_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Create vector stores with automatic persistence\n",
        "# When persist_directory is provided, Chroma automatically persists to disk\n",
        "dense_vs = Chroma.from_documents(\n",
        "    documents=dense_chunks,\n",
        "    embedding=embeddings, \n",
        "    collection_name=\"fastapi_dense_docs\",\n",
        "    persist_directory=str(vectordb_dir / \"dense\"),\n",
        ")\n",
        "\n",
        "faq_vs = Chroma.from_documents(\n",
        "    documents=faq_chunks,\n",
        "    embedding=embeddings, \n",
        "    collection_name=\"fastapi_faq_docs\",\n",
        "    persist_directory=str(vectordb_dir / \"faq\"),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0cf66f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create retrievers with search configuration\n",
        "# Using the modern LangChain API with search_kwargs\n",
        "dense_retriever = dense_vs.as_retriever(search_kwargs={\"k\": 4})\n",
        "faq_retriever = faq_vs.as_retriever(search_kwargs={\"k\": 2})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfad7805",
      "metadata": {},
      "source": [
        "## **Implement routing (which corpus, which strategy)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5009024e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def route_query(query: str) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Route a query to the appropriate corpus(es) using rule-based logic.\n",
        "    \n",
        "    NOTE: faq_docs corpus is limited (single README.md), so routing is conservative.\n",
        "    Only routes to faq_docs for very specific error/troubleshooting queries.\n",
        "    \n",
        "    Args:\n",
        "        query: The user's search query\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary with \"corpus\" key set to \"dense_docs\", \"faq_docs\", or \"both\"\n",
        "    \"\"\"\n",
        "    query_lower = query.lower()\n",
        "    \n",
        "    # Step 1: Keyword-based routing\n",
        "    # FAQ indicators: STRONG error/debugging signals only (faq_docs is limited)\n",
        "    # Only route to faq_docs for very specific troubleshooting queries\n",
        "    strong_faq_keywords = [\n",
        "        \"500\", \"404\", \"403\", \"401\", \"400\",  # HTTP error codes\n",
        "        \"stack trace\", \"traceback\",  # Specific error indicators\n",
        "        \"doesn't work\", \"not working\", \"broken\",  # Clear problem statements\n",
        "        \"troubleshoot\", \"debug\",  # Explicit debugging intent\n",
        "    ]\n",
        "    \n",
        "    # Moderate FAQ indicators: may use \"both\" for these\n",
        "    moderate_faq_keywords = [\n",
        "        \"error\", \"exception\", \"failed\", \"failure\", \"crash\", \"issue\", \"bug\", \"problem\"\n",
        "    ]\n",
        "    \n",
        "    # Dense docs indicators: tutorials, guides, concepts, best practices\n",
        "    # Note: \"best practices\" queries go to dense_docs since faq_docs is limited\n",
        "    dense_keywords = [\n",
        "        \"tutorial\", \"how to\", \"how do\", \"guide\", \"best practices\", \"best practice\",\n",
        "        \"architecture\", \"design\", \"deployment\", \"security\", \"dependency injection\",\n",
        "        \"background tasks\", \"middleware\", \"async\", \"asynchronous\", \"concurrency\",\n",
        "        \"testing\", \"cors\", \"authentication\", \"authorization\", \"validation\",\n",
        "        \"pydantic\", \"openapi\", \"swagger\", \"websocket\", \"websockets\",\n",
        "        \"project structure\", \"structure\", \"conventions\", \"patterns\"\n",
        "    ]\n",
        "    \n",
        "    # Count matches\n",
        "    strong_faq_score = sum(1 for keyword in strong_faq_keywords if keyword in query_lower)\n",
        "    moderate_faq_score = sum(1 for keyword in moderate_faq_keywords if keyword in query_lower)\n",
        "    dense_score = sum(1 for keyword in dense_keywords if keyword in query_lower)\n",
        "    \n",
        "    # Step 2: Query length analysis\n",
        "    query_length = len(query.split())\n",
        "    is_short_query = query_length <= 3\n",
        "    is_long_query = query_length > 10\n",
        "    \n",
        "    # Step 3: Decision logic (conservative - favor dense_docs)\n",
        "    \n",
        "    # Very strong FAQ signal (error codes, explicit debugging) → faq_docs\n",
        "    if strong_faq_score > 0:\n",
        "        return {\"corpus\": \"faq_docs\"}\n",
        "    \n",
        "    # Strong dense signal → dense_docs\n",
        "    if dense_score > 0 and dense_score > moderate_faq_score:\n",
        "        return {\"corpus\": \"dense_docs\"}\n",
        "    \n",
        "    # Moderate FAQ + dense signals → use both (faq might have relevant troubleshooting)\n",
        "    if moderate_faq_score > 0 and dense_score > 0:\n",
        "        return {\"corpus\": \"both\"}\n",
        "    \n",
        "    # Moderate FAQ only, but query is long/specific → both (to be safe)\n",
        "    if moderate_faq_score > 0 and is_long_query:\n",
        "        return {\"corpus\": \"both\"}\n",
        "    \n",
        "    # Moderate FAQ only, short query → dense_docs (faq_docs too limited)\n",
        "    if moderate_faq_score > 0:\n",
        "        return {\"corpus\": \"dense_docs\"}\n",
        "    \n",
        "    # Short, generic queries → dense_docs (tutorials/guides)\n",
        "    if is_short_query:\n",
        "        return {\"corpus\": \"dense_docs\"}\n",
        "    \n",
        "    # Default: dense_docs (more comprehensive corpus)\n",
        "    return {\"corpus\": \"dense_docs\"}\n",
        "\n",
        "\n",
        "def get_retriever_for_query(query: str, dense_retriever, faq_retriever):\n",
        "    \"\"\"\n",
        "    Get the appropriate retriever(s) based on query routing.\n",
        "    \n",
        "    Args:\n",
        "        query: The user's search query\n",
        "        dense_retriever: Retriever for dense_docs corpus\n",
        "        faq_retriever: Retriever for faq_docs corpus\n",
        "        \n",
        "    Returns:\n",
        "        Single retriever or list of retrievers based on routing decision\n",
        "    \"\"\"\n",
        "    routing = route_query(query)\n",
        "    corpus = routing[\"corpus\"]\n",
        "    \n",
        "    if corpus == \"dense_docs\":\n",
        "        return dense_retriever\n",
        "    elif corpus == \"faq_docs\":\n",
        "        return faq_retriever\n",
        "    else:  # \"both\"\n",
        "        return [dense_retriever, faq_retriever]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625eb790",
      "metadata": {},
      "source": [
        "## **Implement query translation (multi-query, maybe HyDE later)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5a5e013a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Multi Query: Different Perspectives\n",
        "template = \"\"\"You are an AI language model assistant. Your task is to generate three \n",
        "different versions of the given user question to retrieve relevant documents from a vector \n",
        "database. By generating multiple perspectives on the user question, your goal is to help\n",
        "the user overcome some of the limitations of the distance-based similarity search. \n",
        "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
        "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "generate_queries = (\n",
        "    prompt_perspectives \n",
        "    | llm\n",
        "    | StrOutputParser() \n",
        "    # Split on newlines, strip whitespace, drop empties, and cap to 3 variants\n",
        "    | (lambda x: [q.strip() for q in x.split(\"\\n\") if q.strip()][:3])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "125bda06",
      "metadata": {},
      "source": [
        "## **Retrieval + fusion + answer generation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7627d367",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Dependency injection in FastAPI is a system that allows your code to declare things it requires to work and use, called \"dependencies.\" FastAPI will then take care of providing these dependencies to your code. This is useful for shared logic, database connections, security, authentication, and more. \\n\\nTo use dependency injection in FastAPI, you can define dependencies that can be injected into your path operation functions. You can do this by using the `Depends` class and passing the dependency to it. For example:\\n```\\nfrom fastapi import FastAPI, Depends\\n\\napp = FastAPI()\\n\\ndef dependency_function():\\n    # This is a dependency function that returns a value\\n    return \"Dependency value\"\\n\\n@app.get(\"/\")\\ndef read_root(dependency: str = Depends(dependency_function)):\\n    # This is a path operation function that depends on the dependency function\\n    return {\"dependency\": dependency}\\n```\\nIn this example, the `read_root` function depends on the `dependency_function`, which is injected into it using the `Depends` class. \\n\\nYou can also use dependency injection to share database connections, enforce security, authentication, role requirements, and more. FastAPI\\'s dependency injection system is designed to be simple to use and makes it easy to integrate other components with FastAPI. \\n\\nAdditionally, FastAPI\\'s dependency injection system is compatible with a wide range of databases, external packages, external APIs, authentication and authorization systems, and more. \\n\\nYou can define dependencies that in turn can define dependencies themselves, making the system very powerful and flexible. \\n\\nIt\\'s worth noting that you don\\'t need to create \"plug-ins\" to use dependency injection in FastAPI, as you can declare an infinite number of integrations and interactions that become available to your path operation functions using dependencies. \\n\\nYou will see examples of how to use dependency injection in the next chapters, about relational and NoSQL databases, security, etc.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.load import dumps, loads\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "def get_unique_union(documents: list[list]):\n",
        "    \"\"\"Unique union of retrieved docs from a list of lists.\"\"\"\n",
        "    # Flatten list of lists, and convert each Document to string\n",
        "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
        "    # Get unique documents\n",
        "    unique_docs = list(set(flattened_docs))\n",
        "    # Return Documents reconstructed from their string representation\n",
        "    return [loads(doc) for doc in unique_docs]\n",
        "\n",
        "\n",
        "def retrieve_multi_corpus(queries: list[str]):\n",
        "    \"\"\"Retrieve documents for multiple query variants across routed corpora.\n",
        "\n",
        "    - Takes the list of reformulated queries from `generate_queries`.\n",
        "    - Uses `get_retriever_for_query` to decide which retriever(s) to use.\n",
        "    - Returns a list-of-lists of Documents, one sublist per query, suitable for\n",
        "      `get_unique_union`.\n",
        "    \"\"\"\n",
        "    all_results: list[list] = []\n",
        "    for q in queries:\n",
        "        retriever_or_list = get_retriever_for_query(q, dense_retriever, faq_retriever)\n",
        "        docs_for_q = []\n",
        "        # Handle the case where routing returns multiple retrievers (\"both\")\n",
        "        if isinstance(retriever_or_list, list):\n",
        "            for r in retriever_or_list:\n",
        "                docs_for_q.extend(r.invoke(q))\n",
        "        else:\n",
        "            docs_for_q.extend(retriever_or_list.invoke(q))\n",
        "        all_results.append(docs_for_q)\n",
        "    return all_results\n",
        "\n",
        "\n",
        "# Full retrieval chain: question -> multi-query -> routed retrieval -> dedup\n",
        "retrieval_chain = (\n",
        "    generate_queries\n",
        "    | RunnableLambda(retrieve_multi_corpus)\n",
        "    | get_unique_union\n",
        ")\n",
        "\n",
        "# RAG Chain\n",
        "template = \"\"\"Answer the following question based on this context:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "final_rag_chain = (\n",
        "    {\"context\": retrieval_chain, \n",
        "     \"question\": itemgetter(\"question\")} \n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "question = \"What is dependency injection in FastAPI and how do I use it?\"\n",
        "final_rag_chain.invoke({\"question\":question})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a86803ff",
      "metadata": {},
      "source": [
        "## **Small evaluation loop**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c278c7f1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Q: What is dependency injection in FastAPI and how do I use it?\n",
            "Score (keyword coverage): 1.00\n",
            "Sources:\n",
            "  - /Users/dimitar/Desktop/Software_Dev/rag-learning/fastapi/docs/en/docs/tutorial/dependencies/index.md\n",
            "Answer snippet:\n",
            "Dependency injection in FastAPI is a system that allows you to declare things that your code requires to work and use, and then the system takes care of providing those dependencies. This is useful when you need to have shared logic, share database connections, enforce security, authentication, role requirements, etc. To use dependency injection in FastAPI, you can define dependencies that can ...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 89\u001b[39m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Example usage (uncomment to run):\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m eval_results = \u001b[43mrun_small_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow_sources\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mrun_small_eval\u001b[39m\u001b[34m(show_sources)\u001b[39m\n\u001b[32m     49\u001b[39m keywords = ex.get(\u001b[33m\"\u001b[39m\u001b[33mkeywords\u001b[39m\u001b[33m\"\u001b[39m, [])\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Generate answer with current RAG pipeline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m answer = \u001b[43mfinal_rag_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m score = score_answer_keywords(answer, keywords)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Inspect retrieval for debugging (optional)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3129\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3127\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3128\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3129\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3131\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/langchain_groq/chat_models.py:590\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    585\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    586\u001b[39m params = {\n\u001b[32m    587\u001b[39m     **params,\n\u001b[32m    588\u001b[39m     **kwargs,\n\u001b[32m    589\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, params)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/groq/resources/chat/completions.py:464\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, citation_options, compound_custom, disable_tool_validation, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    245\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    246\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    303\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    304\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    305\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    307\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    462\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcitation_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcitation_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompound_custom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompound_custom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdisable_tool_validation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_tool_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_reasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/groq/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/groq/_base_client.py:980\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    978\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    979\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    986\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Software_Dev/rag-learning/rag-learning/venv/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1285\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1283\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1284\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1140\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from typing import List, Dict, Any\n",
        "import textwrap\n",
        "\n",
        "# Small, cheap evaluation set tailored to FastAPI docs\n",
        "EVAL_QUESTIONS: List[Dict[str, Any]] = [\n",
        "    {\n",
        "        \"question\": \"What is dependency injection in FastAPI and how do I use it?\",\n",
        "        \"keywords\": [\"Depends\", \"dependency injection\"],\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How do I define a Pydantic model for a request body in FastAPI?\",\n",
        "        \"keywords\": [\"BaseModel\", \"request body\", \"pydantic\"],\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How can I run background tasks in FastAPI?\",\n",
        "        \"keywords\": [\"BackgroundTasks\", \"background task\"],\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How do I enable CORS in FastAPI?\",\n",
        "        \"keywords\": [\"CORSMiddleware\", \"add_middleware\"],\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How do I declare path and query parameters in FastAPI?\",\n",
        "        \"keywords\": [\"path parameter\", \"query parameter\", \"type hints\"],\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "def score_answer_keywords(answer: str, keywords: List[str]) -> float:\n",
        "    \"\"\"Very small heuristic: fraction of keywords that appear in the answer.\"\"\"\n",
        "    answer_lower = answer.lower()\n",
        "    if not keywords:\n",
        "        return 0.0\n",
        "    hits = sum(1 for kw in keywords if kw.lower() in answer_lower)\n",
        "    return hits / len(keywords)\n",
        "\n",
        "\n",
        "def run_small_eval(show_sources: bool = False) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Run a lightweight eval loop over EVAL_QUESTIONS.\n",
        "\n",
        "    - Uses `final_rag_chain` to generate answers.\n",
        "    - Scores answers by keyword coverage (0–1).\n",
        "    - Optionally prints which source files were retrieved.\n",
        "    \"\"\"\n",
        "    results: List[Dict[str, Any]] = []\n",
        "\n",
        "    for ex in EVAL_QUESTIONS:\n",
        "        q = ex[\"question\"]\n",
        "        keywords = ex.get(\"keywords\", [])\n",
        "\n",
        "        # Generate answer with current RAG pipeline\n",
        "        answer = final_rag_chain.invoke({\"question\": q})\n",
        "        score = score_answer_keywords(answer, keywords)\n",
        "\n",
        "        # Inspect retrieval for debugging (optional)\n",
        "        sources = []\n",
        "        if show_sources:\n",
        "            docs = retrieval_chain.invoke({\"question\": q})\n",
        "            sources = sorted({d.metadata.get(\"source\", \"\") for d in docs})\n",
        "\n",
        "        result = {\n",
        "            \"question\": q,\n",
        "            \"keywords\": keywords,\n",
        "            \"score\": score,\n",
        "            \"answer\": answer,\n",
        "            \"sources\": sources,\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "        # Compact console view\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(f\"Q: {q}\")\n",
        "        print(f\"Score (keyword coverage): {score:.2f}\")\n",
        "        if show_sources and sources:\n",
        "            print(\"Sources:\")\n",
        "            for s in sources[:5]:\n",
        "                print(f\"  - {s}\")\n",
        "        print(\"Answer snippet:\")\n",
        "        print(textwrap.shorten(answer.replace(\"\\n\", \" \"), width=400, placeholder=\" ...\"))\n",
        "\n",
        "    avg_score = sum(r[\"score\"] for r in results) / len(results)\n",
        "    print(\"\\n\" + \"#\" * 80)\n",
        "    print(f\"Average keyword score over {len(results)} questions: {avg_score:.2f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# Example usage (uncomment to run):\n",
        "# eval_results = run_small_eval(show_sources=True)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.13.2 (rag-learning)",
      "language": "python",
      "name": "rag-learning"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
